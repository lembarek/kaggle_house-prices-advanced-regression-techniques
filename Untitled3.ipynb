{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bib' from '/home/lem/d/develop/machine_learning/kaggle/house-prices-advanced-regression-techniques/bib.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bib\n",
    "importlib.reload(bib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bib.prepare_data(pd)\n",
    "\n",
    "X,y = bib.split_data(data)\n",
    "\n",
    "columns = data.columns\n",
    "\n",
    "category_columns = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
    "    'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
    "    'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "    'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
    "    'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "    'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
    "    'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
    "    'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "    'SaleType', 'SaleCondition'];\n",
    "\n",
    "X = X[columns.drop(['Id', 'SalePrice'])]\n",
    "\n",
    "import category_encoders as ce\n",
    "ce_one_hot = ce.OneHotEncoder(cols = category_columns)\n",
    "ce = ce_one_hot.fit(X)\n",
    "X = ce.transform(X)\n",
    "\n",
    "X = bib.prepare_X(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "X_train, X_valid , y_train, y_valid = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 13:46:55.493684 140670015190656 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1314 samples, validate on 146 samples\n",
      "Epoch 1/400\n",
      "1314/1314 [==============================] - 0s 221us/sample - loss: 181621.9148 - mse: 39417499648.0000 - val_loss: 174569.3018 - val_mse: 35620466688.0000\n",
      "Epoch 2/400\n",
      "1314/1314 [==============================] - 0s 111us/sample - loss: 181569.3423 - mse: 39397236736.0000 - val_loss: 174427.8889 - val_mse: 35568119808.0000\n",
      "Epoch 3/400\n",
      "1314/1314 [==============================] - 0s 114us/sample - loss: 181123.9860 - mse: 39222910976.0000 - val_loss: 173492.5760 - val_mse: 35218710528.0000\n",
      "Epoch 4/400\n",
      "1314/1314 [==============================] - 0s 105us/sample - loss: 179074.7060 - mse: 38433484800.0000 - val_loss: 170018.2729 - val_mse: 33941712896.0000\n",
      "Epoch 5/400\n",
      "1314/1314 [==============================] - 0s 104us/sample - loss: 172977.3128 - mse: 36145459200.0000 - val_loss: 161056.5163 - val_mse: 30770700288.0000\n",
      "Epoch 6/400\n",
      "1314/1314 [==============================] - 0s 127us/sample - loss: 159273.1920 - mse: 31257016320.0000 - val_loss: 142363.7640 - val_mse: 24778563584.0000\n",
      "Epoch 7/400\n",
      "1314/1314 [==============================] - 0s 120us/sample - loss: 133321.9516 - mse: 23047219200.0000 - val_loss: 110262.9778 - val_mse: 16228519936.0000\n",
      "Epoch 8/400\n",
      "1314/1314 [==============================] - 0s 113us/sample - loss: 94537.6530 - mse: 13173942272.0000 - val_loss: 69975.6514 - val_mse: 8182437376.0000\n",
      "Epoch 9/400\n",
      "1314/1314 [==============================] - 0s 123us/sample - loss: 59861.6203 - mse: 6591903232.0000 - val_loss: 51413.0359 - val_mse: 5404060672.0000\n",
      "Epoch 10/400\n",
      "1314/1314 [==============================] - 0s 121us/sample - loss: 49795.9677 - mse: 4846223872.0000 - val_loss: 47412.3245 - val_mse: 4760622080.0000\n",
      "Epoch 11/400\n",
      "1314/1314 [==============================] - 0s 110us/sample - loss: 46161.0244 - mse: 4276833792.0000 - val_loss: 44254.3185 - val_mse: 4311458816.0000\n",
      "Epoch 12/400\n",
      "1314/1314 [==============================] - 0s 120us/sample - loss: 43526.5410 - mse: 3868602624.0000 - val_loss: 42158.0063 - val_mse: 4063578624.0000\n",
      "Epoch 13/400\n",
      "1314/1314 [==============================] - 0s 116us/sample - loss: 41625.5988 - mse: 3684995840.0000 - val_loss: 39989.8329 - val_mse: 3819939840.0000\n",
      "Epoch 14/400\n",
      "1314/1314 [==============================] - 0s 109us/sample - loss: 39042.5212 - mse: 3306344960.0000 - val_loss: 38925.0936 - val_mse: 3668087040.0000\n",
      "Epoch 15/400\n",
      "1314/1314 [==============================] - 0s 113us/sample - loss: 37261.2543 - mse: 3046991872.0000 - val_loss: 37903.1828 - val_mse: 3501175040.0000\n",
      "Epoch 16/400\n",
      "1314/1314 [==============================] - 0s 101us/sample - loss: 36237.9408 - mse: 2860869120.0000 - val_loss: 36995.2425 - val_mse: 3381998592.0000\n",
      "Epoch 17/400\n",
      "1314/1314 [==============================] - 0s 100us/sample - loss: 35639.0542 - mse: 2704689152.0000 - val_loss: 36245.1269 - val_mse: 3286430208.0000\n",
      "Epoch 18/400\n",
      "1314/1314 [==============================] - 0s 101us/sample - loss: 35234.5050 - mse: 2746714368.0000 - val_loss: 35542.8486 - val_mse: 3182581760.0000\n",
      "Epoch 19/400\n",
      "1314/1314 [==============================] - 0s 101us/sample - loss: 33888.1290 - mse: 2506096128.0000 - val_loss: 34954.4922 - val_mse: 3098174976.0000\n",
      "Epoch 20/400\n",
      "1314/1314 [==============================] - 0s 112us/sample - loss: 33579.3316 - mse: 2363792128.0000 - val_loss: 34504.6038 - val_mse: 3019229696.0000\n",
      "Epoch 21/400\n",
      "1314/1314 [==============================] - 0s 109us/sample - loss: 32161.8393 - mse: 2338512128.0000 - val_loss: 33943.0339 - val_mse: 2932108544.0000\n",
      "Epoch 22/400\n",
      "1314/1314 [==============================] - 0s 109us/sample - loss: 32142.7676 - mse: 2223539712.0000 - val_loss: 33937.6977 - val_mse: 2884892416.0000\n",
      "Epoch 23/400\n",
      "1314/1314 [==============================] - 0s 110us/sample - loss: 31033.0073 - mse: 2134890112.0000 - val_loss: 33397.6899 - val_mse: 2838447104.0000\n",
      "Epoch 24/400\n",
      "1314/1314 [==============================] - 0s 108us/sample - loss: 32177.2706 - mse: 2275801344.0000 - val_loss: 33137.1006 - val_mse: 2828314624.0000\n",
      "Epoch 25/400\n",
      "1314/1314 [==============================] - 0s 97us/sample - loss: 30989.7829 - mse: 2115398912.0000 - val_loss: 32888.2136 - val_mse: 2771186944.0000\n",
      "Epoch 26/400\n",
      "1314/1314 [==============================] - 0s 103us/sample - loss: 30480.6513 - mse: 2040544000.0000 - val_loss: 32400.7386 - val_mse: 2727371776.0000\n",
      "Epoch 27/400\n",
      "1314/1314 [==============================] - 0s 113us/sample - loss: 29967.0089 - mse: 1929956736.0000 - val_loss: 32022.4859 - val_mse: 2700094720.0000\n",
      "Epoch 28/400\n",
      "1314/1314 [==============================] - 0s 108us/sample - loss: 30120.0993 - mse: 1959045248.0000 - val_loss: 31892.8651 - val_mse: 2655133952.0000\n",
      "Epoch 29/400\n",
      "1314/1314 [==============================] - 0s 102us/sample - loss: 29221.0584 - mse: 1875263488.0000 - val_loss: 31895.4828 - val_mse: 2648707328.0000\n",
      "Epoch 30/400\n",
      "1314/1314 [==============================] - 0s 96us/sample - loss: 29976.5831 - mse: 1940527360.0000 - val_loss: 31534.8873 - val_mse: 2610582784.0000\n",
      "Epoch 31/400\n",
      "1314/1314 [==============================] - 0s 115us/sample - loss: 29654.7696 - mse: 1839984384.0000 - val_loss: 31289.4455 - val_mse: 2571966720.0000\n",
      "Epoch 32/400\n",
      "1314/1314 [==============================] - 0s 109us/sample - loss: 28997.1995 - mse: 1826824832.0000 - val_loss: 31008.2686 - val_mse: 2551388160.0000\n",
      "Epoch 33/400\n",
      "1314/1314 [==============================] - 0s 105us/sample - loss: 28575.0977 - mse: 1796920320.0000 - val_loss: 30622.2484 - val_mse: 2514756608.0000\n",
      "Epoch 34/400\n",
      "1314/1314 [==============================] - 0s 116us/sample - loss: 27981.8212 - mse: 1666087808.0000 - val_loss: 30724.2992 - val_mse: 2514511616.0000\n",
      "Epoch 35/400\n",
      "1314/1314 [==============================] - 0s 143us/sample - loss: 27133.1727 - mse: 1638756864.0000 - val_loss: 30147.2264 - val_mse: 2459648000.0000\n",
      "Epoch 36/400\n",
      "1314/1314 [==============================] - 0s 118us/sample - loss: 28174.2629 - mse: 1792483840.0000 - val_loss: 30282.9012 - val_mse: 2467494400.0000\n",
      "Epoch 37/400\n",
      "1314/1314 [==============================] - 0s 93us/sample - loss: 27148.9878 - mse: 1627051392.0000 - val_loss: 30211.1523 - val_mse: 2456155136.0000\n",
      "Epoch 38/400\n",
      "1314/1314 [==============================] - 0s 128us/sample - loss: 27110.9274 - mse: 1623186432.0000 - val_loss: 29941.1961 - val_mse: 2421339648.0000\n",
      "Epoch 39/400\n",
      "1314/1314 [==============================] - 0s 100us/sample - loss: 26373.2805 - mse: 1448139904.0000 - val_loss: 29711.3783 - val_mse: 2382034944.0000\n",
      "Epoch 40/400\n",
      "1314/1314 [==============================] - 0s 102us/sample - loss: 26862.5404 - mse: 1574374784.0000 - val_loss: 29649.6003 - val_mse: 2379298560.0000\n",
      "Epoch 41/400\n",
      "1314/1314 [==============================] - 0s 108us/sample - loss: 26786.2192 - mse: 1504043008.0000 - val_loss: 29852.5419 - val_mse: 2402921984.0000\n",
      "Epoch 42/400\n",
      "1314/1314 [==============================] - 0s 96us/sample - loss: 26908.1335 - mse: 1536339328.0000 - val_loss: 29961.9169 - val_mse: 2403275264.0000\n",
      "Epoch 43/400\n",
      "1314/1314 [==============================] - 0s 111us/sample - loss: 26203.4714 - mse: 1526192640.0000 - val_loss: 29401.6858 - val_mse: 2352557312.0000\n",
      "Epoch 44/400\n",
      "1314/1314 [==============================] - 0s 98us/sample - loss: 26681.7358 - mse: 1545814400.0000 - val_loss: 29044.8122 - val_mse: 2325673472.0000\n",
      "Epoch 45/400\n",
      "1314/1314 [==============================] - 0s 105us/sample - loss: 26064.3167 - mse: 1546097152.0000 - val_loss: 29172.6635 - val_mse: 2328412672.0000\n",
      "Epoch 46/400\n",
      "1314/1314 [==============================] - 0s 120us/sample - loss: 27005.0494 - mse: 1527102976.0000 - val_loss: 29224.4457 - val_mse: 2322453760.0000\n",
      "Epoch 47/400\n",
      "1314/1314 [==============================] - 0s 108us/sample - loss: 27037.0336 - mse: 1561368320.0000 - val_loss: 29258.7247 - val_mse: 2315952384.0000\n",
      "Epoch 48/400\n",
      "1314/1314 [==============================] - 0s 89us/sample - loss: 25775.7471 - mse: 1388038528.0000 - val_loss: 29064.2654 - val_mse: 2291211008.0000\n",
      "Epoch 49/400\n",
      "1314/1314 [==============================] - 0s 98us/sample - loss: 25981.1075 - mse: 1512949504.0000 - val_loss: 29065.7516 - val_mse: 2287942912.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/400\n",
      "1314/1314 [==============================] - 0s 119us/sample - loss: 26309.0334 - mse: 1447810304.0000 - val_loss: 29088.7475 - val_mse: 2289259008.0000\n",
      "Epoch 51/400\n",
      "1314/1314 [==============================] - 0s 101us/sample - loss: 25869.1302 - mse: 1451914752.0000 - val_loss: 29046.5967 - val_mse: 2275502592.0000\n",
      "Epoch 52/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 25575.3132 - mse: 1427780608.0000 - val_loss: 28747.3527 - val_mse: 2267435008.0000\n",
      "Epoch 53/400\n",
      "1314/1314 [==============================] - 0s 114us/sample - loss: 24863.8435 - mse: 1336473216.0000 - val_loss: 28643.3441 - val_mse: 2260306176.0000\n",
      "Epoch 54/400\n",
      "1314/1314 [==============================] - 0s 103us/sample - loss: 26332.9894 - mse: 1554693504.0000 - val_loss: 28648.8930 - val_mse: 2269566208.0000\n",
      "Epoch 55/400\n",
      "1314/1314 [==============================] - 0s 93us/sample - loss: 25284.1078 - mse: 1355507584.0000 - val_loss: 28631.6702 - val_mse: 2250307584.0000\n",
      "Epoch 56/400\n",
      "1314/1314 [==============================] - 0s 84us/sample - loss: 25272.1421 - mse: 1361831168.0000 - val_loss: 28864.8577 - val_mse: 2260519168.0000\n",
      "Epoch 57/400\n",
      "1314/1314 [==============================] - 0s 83us/sample - loss: 24591.8559 - mse: 1307356032.0000 - val_loss: 28603.3854 - val_mse: 2232112128.0000\n",
      "Epoch 58/400\n",
      "1314/1314 [==============================] - 0s 85us/sample - loss: 24548.9018 - mse: 1272470656.0000 - val_loss: 28425.1273 - val_mse: 2217489664.0000\n",
      "Epoch 59/400\n",
      "1314/1314 [==============================] - 0s 80us/sample - loss: 24767.5613 - mse: 1375828224.0000 - val_loss: 28334.1390 - val_mse: 2221079552.0000\n",
      "Epoch 60/400\n",
      "1314/1314 [==============================] - 0s 91us/sample - loss: 24743.0024 - mse: 1343030528.0000 - val_loss: 28092.0155 - val_mse: 2198170112.0000\n",
      "Epoch 61/400\n",
      "1314/1314 [==============================] - 0s 80us/sample - loss: 24865.9868 - mse: 1370561664.0000 - val_loss: 28002.2996 - val_mse: 2186335744.0000\n",
      "Epoch 62/400\n",
      "1314/1314 [==============================] - 0s 81us/sample - loss: 24608.7001 - mse: 1297830528.0000 - val_loss: 27878.1613 - val_mse: 2186668544.0000\n",
      "Epoch 63/400\n",
      "1314/1314 [==============================] - 0s 79us/sample - loss: 24772.2995 - mse: 1313857536.0000 - val_loss: 27993.2952 - val_mse: 2190679040.0000\n",
      "Epoch 64/400\n",
      "1314/1314 [==============================] - 0s 75us/sample - loss: 24391.5875 - mse: 1218947200.0000 - val_loss: 28109.7400 - val_mse: 2195314176.0000\n",
      "Epoch 65/400\n",
      "1314/1314 [==============================] - 0s 79us/sample - loss: 23970.2044 - mse: 1241277440.0000 - val_loss: 27752.3102 - val_mse: 2161793280.0000\n",
      "Epoch 66/400\n",
      "1314/1314 [==============================] - 0s 79us/sample - loss: 24125.6395 - mse: 1269157888.0000 - val_loss: 28120.6199 - val_mse: 2182247680.0000\n",
      "Epoch 67/400\n",
      "1314/1314 [==============================] - 0s 75us/sample - loss: 23918.5423 - mse: 1239338880.0000 - val_loss: 27792.4366 - val_mse: 2162197504.0000\n",
      "Epoch 68/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 24080.5598 - mse: 1360435584.0000 - val_loss: 27950.0443 - val_mse: 2170190080.0000\n",
      "Epoch 69/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 25210.0147 - mse: 1419755008.0000 - val_loss: 27932.4998 - val_mse: 2155853568.0000\n",
      "Epoch 70/400\n",
      "1314/1314 [==============================] - 0s 79us/sample - loss: 23566.6794 - mse: 1151132288.0000 - val_loss: 27565.6318 - val_mse: 2128991232.0000\n",
      "Epoch 71/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 23635.7410 - mse: 1196287104.0000 - val_loss: 27380.5504 - val_mse: 2116405248.0000\n",
      "Epoch 72/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 23775.8445 - mse: 1172836096.0000 - val_loss: 27410.4362 - val_mse: 2125286656.0000\n",
      "Epoch 73/400\n",
      "1314/1314 [==============================] - 0s 76us/sample - loss: 23330.2206 - mse: 1194451840.0000 - val_loss: 27605.6171 - val_mse: 2140871424.0000\n",
      "Epoch 74/400\n",
      "1314/1314 [==============================] - 0s 78us/sample - loss: 23788.7371 - mse: 1210953600.0000 - val_loss: 27626.4516 - val_mse: 2141330176.0000\n",
      "Epoch 75/400\n",
      "1314/1314 [==============================] - 0s 81us/sample - loss: 23751.6329 - mse: 1118257664.0000 - val_loss: 27497.3010 - val_mse: 2129332864.0000\n",
      "Epoch 76/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 23702.6195 - mse: 1209423744.0000 - val_loss: 27315.7493 - val_mse: 2104865536.0000\n",
      "Epoch 77/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 23888.7446 - mse: 1201765376.0000 - val_loss: 27327.4240 - val_mse: 2108420608.0000\n",
      "Epoch 78/400\n",
      "1314/1314 [==============================] - 0s 83us/sample - loss: 23608.5284 - mse: 1106555648.0000 - val_loss: 27415.5546 - val_mse: 2112836864.0000\n",
      "Epoch 79/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 22852.2623 - mse: 1176844672.0000 - val_loss: 27447.9945 - val_mse: 2113860736.0000\n",
      "Epoch 80/400\n",
      "1314/1314 [==============================] - 0s 83us/sample - loss: 23144.6803 - mse: 1154265856.0000 - val_loss: 27389.5192 - val_mse: 2103720448.0000\n",
      "Epoch 81/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 23256.1285 - mse: 1118643200.0000 - val_loss: 27754.8405 - val_mse: 2117315968.0000\n",
      "Epoch 82/400\n",
      "1314/1314 [==============================] - 0s 79us/sample - loss: 22812.1504 - mse: 1057110144.0000 - val_loss: 27380.1432 - val_mse: 2081244672.0000\n",
      "Epoch 83/400\n",
      "1314/1314 [==============================] - 0s 82us/sample - loss: 23843.1867 - mse: 1222124160.0000 - val_loss: 27419.7076 - val_mse: 2092417920.0000\n",
      "Epoch 84/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 23536.5301 - mse: 1130482304.0000 - val_loss: 27441.3675 - val_mse: 2086489600.0000\n",
      "Epoch 85/400\n",
      "1314/1314 [==============================] - 0s 81us/sample - loss: 23105.0417 - mse: 1201007104.0000 - val_loss: 27264.1328 - val_mse: 2078808832.0000\n",
      "Epoch 86/400\n",
      "1314/1314 [==============================] - 0s 78us/sample - loss: 23423.9434 - mse: 1179346432.0000 - val_loss: 27336.5245 - val_mse: 2073622784.0000\n",
      "Epoch 87/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 23390.2915 - mse: 1090597888.0000 - val_loss: 27179.8042 - val_mse: 2061671680.0000\n",
      "Epoch 88/400\n",
      "1314/1314 [==============================] - 0s 81us/sample - loss: 23288.7107 - mse: 1140813440.0000 - val_loss: 27188.1900 - val_mse: 2069528320.0000\n",
      "Epoch 89/400\n",
      "1314/1314 [==============================] - 0s 79us/sample - loss: 22401.7561 - mse: 1102714240.0000 - val_loss: 27427.3252 - val_mse: 2078483200.0000\n",
      "Epoch 90/400\n",
      "1314/1314 [==============================] - 0s 78us/sample - loss: 22679.0679 - mse: 1018886400.0000 - val_loss: 26922.1373 - val_mse: 2055635200.0000\n",
      "Epoch 91/400\n",
      "1314/1314 [==============================] - 0s 81us/sample - loss: 23249.5893 - mse: 1177630080.0000 - val_loss: 27240.3605 - val_mse: 2073973760.0000\n",
      "Epoch 92/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 23103.3875 - mse: 1093025152.0000 - val_loss: 27292.2649 - val_mse: 2069590528.0000\n",
      "Epoch 93/400\n",
      "1314/1314 [==============================] - 0s 78us/sample - loss: 23587.7136 - mse: 1279207808.0000 - val_loss: 27489.7186 - val_mse: 2073744000.0000\n",
      "Epoch 94/400\n",
      "1314/1314 [==============================] - 0s 79us/sample - loss: 23526.6756 - mse: 1164150784.0000 - val_loss: 27424.1621 - val_mse: 2073721984.0000\n",
      "Epoch 95/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 22668.5386 - mse: 1100087040.0000 - val_loss: 27264.9479 - val_mse: 2066384256.0000\n",
      "Epoch 96/400\n",
      "1314/1314 [==============================] - 0s 78us/sample - loss: 22191.4094 - mse: 1022434304.0000 - val_loss: 27508.6132 - val_mse: 2079179648.0000\n",
      "Epoch 97/400\n",
      "1314/1314 [==============================] - 0s 78us/sample - loss: 23412.1099 - mse: 1158993024.0000 - val_loss: 26915.9413 - val_mse: 2050250240.0000\n",
      "Epoch 98/400\n",
      "1314/1314 [==============================] - 0s 83us/sample - loss: 23262.0499 - mse: 1150819968.0000 - val_loss: 27317.9700 - val_mse: 2064200576.0000\n",
      "Epoch 99/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314/1314 [==============================] - 0s 76us/sample - loss: 21630.5018 - mse: 961305984.0000 - val_loss: 27532.5645 - val_mse: 2068081792.0000\n",
      "Epoch 100/400\n",
      "1314/1314 [==============================] - 0s 76us/sample - loss: 22970.5009 - mse: 1110758912.0000 - val_loss: 27439.3489 - val_mse: 2063005440.0000\n",
      "Epoch 101/400\n",
      "1314/1314 [==============================] - 0s 78us/sample - loss: 22899.2810 - mse: 1152769280.0000 - val_loss: 27467.5043 - val_mse: 2057405056.0000\n",
      "Epoch 102/400\n",
      "1314/1314 [==============================] - 0s 80us/sample - loss: 21639.7724 - mse: 986122496.0000 - val_loss: 27224.6973 - val_mse: 2032968064.0000\n",
      "Epoch 103/400\n",
      "1314/1314 [==============================] - 0s 76us/sample - loss: 22424.6297 - mse: 1093133184.0000 - val_loss: 26974.8523 - val_mse: 2030098816.0000\n",
      "Epoch 104/400\n",
      "1314/1314 [==============================] - 0s 83us/sample - loss: 22786.3426 - mse: 1077691008.0000 - val_loss: 27019.4475 - val_mse: 2034555520.0000\n",
      "Epoch 105/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 22793.9253 - mse: 1123471488.0000 - val_loss: 26788.0733 - val_mse: 2035550464.0000\n",
      "Epoch 106/400\n",
      "1314/1314 [==============================] - 0s 79us/sample - loss: 22951.9176 - mse: 1056772608.0000 - val_loss: 27182.0056 - val_mse: 2049558528.0000\n",
      "Epoch 107/400\n",
      "1314/1314 [==============================] - 0s 79us/sample - loss: 22829.7166 - mse: 1046021568.0000 - val_loss: 27107.5045 - val_mse: 2043242624.0000\n",
      "Epoch 108/400\n",
      "1314/1314 [==============================] - 0s 76us/sample - loss: 22004.5603 - mse: 1028079680.0000 - val_loss: 27268.6674 - val_mse: 2047672320.0000\n",
      "Epoch 109/400\n",
      "1314/1314 [==============================] - 0s 80us/sample - loss: 22072.3838 - mse: 968465792.0000 - val_loss: 27017.4430 - val_mse: 2034656256.0000\n",
      "Epoch 110/400\n",
      "1314/1314 [==============================] - 0s 77us/sample - loss: 22719.4319 - mse: 1101479936.0000 - val_loss: 26894.2254 - val_mse: 2028012160.0000\n",
      "Epoch 111/400\n",
      "1314/1314 [==============================] - 0s 83us/sample - loss: 22143.6892 - mse: 995811328.0000 - val_loss: 27054.7353 - val_mse: 2036217216.0000\n",
      "Epoch 112/400\n",
      "1314/1314 [==============================] - 0s 76us/sample - loss: 22312.8687 - mse: 972143936.0000 - val_loss: 26622.4178 - val_mse: 2012098560.0000\n",
      "Epoch 113/400\n",
      "1314/1314 [==============================] - 0s 110us/sample - loss: 22373.1354 - mse: 975515456.0000 - val_loss: 26603.8360 - val_mse: 2011240832.0000\n",
      "Epoch 114/400\n",
      "1314/1314 [==============================] - 0s 108us/sample - loss: 21726.6175 - mse: 943351296.0000 - val_loss: 26899.9488 - val_mse: 2020173184.0000\n",
      "Epoch 115/400\n",
      "1314/1314 [==============================] - 0s 115us/sample - loss: 22185.7588 - mse: 1024519232.0000 - val_loss: 26489.6417 - val_mse: 2001216768.0000\n",
      "Epoch 116/400\n",
      "1314/1314 [==============================] - 0s 93us/sample - loss: 22455.7651 - mse: 1009317568.0000 - val_loss: 26725.9351 - val_mse: 2012459520.0000\n",
      "Epoch 117/400\n",
      "1314/1314 [==============================] - 0s 99us/sample - loss: 21694.3290 - mse: 957808064.0000 - val_loss: 26547.4591 - val_mse: 2000035712.0000\n",
      "Epoch 118/400\n",
      "1314/1314 [==============================] - 0s 104us/sample - loss: 22642.6164 - mse: 1147867008.0000 - val_loss: 26462.3305 - val_mse: 2001905920.0000\n",
      "Epoch 119/400\n",
      "1314/1314 [==============================] - 0s 104us/sample - loss: 21915.5801 - mse: 967102976.0000 - val_loss: 26393.3173 - val_mse: 1992033792.0000\n",
      "Epoch 120/400\n",
      "1314/1314 [==============================] - 0s 104us/sample - loss: 21586.1225 - mse: 932276800.0000 - val_loss: 26617.8625 - val_mse: 2001022336.0000\n",
      "Epoch 121/400\n",
      "1314/1314 [==============================] - 0s 89us/sample - loss: 21587.8287 - mse: 988622720.0000 - val_loss: 26496.9700 - val_mse: 2001464320.0000\n",
      "Epoch 122/400\n",
      "1314/1314 [==============================] - 0s 99us/sample - loss: 21690.9812 - mse: 966613632.0000 - val_loss: 26268.3952 - val_mse: 1979219968.0000\n",
      "Epoch 123/400\n",
      "1314/1314 [==============================] - 0s 102us/sample - loss: 21252.3426 - mse: 947421056.0000 - val_loss: 26382.3775 - val_mse: 1980444928.0000\n",
      "Epoch 124/400\n",
      "1314/1314 [==============================] - 0s 96us/sample - loss: 21884.1069 - mse: 1068041664.0000 - val_loss: 26275.3509 - val_mse: 1984811392.0000\n",
      "Epoch 125/400\n",
      "1314/1314 [==============================] - 0s 93us/sample - loss: 22151.7223 - mse: 1035638976.0000 - val_loss: 26235.7438 - val_mse: 1975747200.0000\n",
      "Epoch 126/400\n",
      "1314/1314 [==============================] - 0s 106us/sample - loss: 21732.6956 - mse: 938371264.0000 - val_loss: 26168.2549 - val_mse: 1968024960.0000\n",
      "Epoch 127/400\n",
      "1314/1314 [==============================] - 0s 97us/sample - loss: 21058.0535 - mse: 944671616.0000 - val_loss: 25963.8559 - val_mse: 1950851840.0000\n",
      "Epoch 128/400\n",
      "1314/1314 [==============================] - 0s 102us/sample - loss: 20741.6009 - mse: 850623296.0000 - val_loss: 26244.7158 - val_mse: 1968912384.0000\n",
      "Epoch 129/400\n",
      "1314/1314 [==============================] - 0s 99us/sample - loss: 21707.4646 - mse: 961858880.0000 - val_loss: 26436.0025 - val_mse: 1982764928.0000\n",
      "Epoch 130/400\n",
      "1314/1314 [==============================] - 0s 91us/sample - loss: 21889.3467 - mse: 1035443392.0000 - val_loss: 26498.5169 - val_mse: 1985213312.0000\n",
      "Epoch 131/400\n",
      "1314/1314 [==============================] - 0s 106us/sample - loss: 20934.7666 - mse: 929683520.0000 - val_loss: 26506.7737 - val_mse: 1988373248.0000\n",
      "Epoch 132/400\n",
      "1314/1314 [==============================] - 0s 93us/sample - loss: 21282.7571 - mse: 949420352.0000 - val_loss: 26146.8130 - val_mse: 1960462080.0000\n",
      "Epoch 133/400\n",
      "1314/1314 [==============================] - 0s 99us/sample - loss: 21991.1773 - mse: 1067066624.0000 - val_loss: 26106.2525 - val_mse: 1958323840.0000\n",
      "Epoch 134/400\n",
      "1314/1314 [==============================] - 0s 102us/sample - loss: 21433.7730 - mse: 926480256.0000 - val_loss: 26115.0331 - val_mse: 1953727872.0000\n",
      "Epoch 135/400\n",
      "1314/1314 [==============================] - 0s 90us/sample - loss: 21567.0501 - mse: 912159488.0000 - val_loss: 25831.0272 - val_mse: 1939157248.0000\n",
      "Epoch 136/400\n",
      "1314/1314 [==============================] - 0s 112us/sample - loss: 22389.0075 - mse: 1061132992.0000 - val_loss: 25977.7672 - val_mse: 1941601152.0000\n",
      "Epoch 137/400\n",
      "1314/1314 [==============================] - 0s 123us/sample - loss: 20465.7594 - mse: 861852864.0000 - val_loss: 26014.7188 - val_mse: 1944577408.0000\n",
      "Epoch 138/400\n",
      "1314/1314 [==============================] - 0s 114us/sample - loss: 21363.0606 - mse: 953016128.0000 - val_loss: 25875.0185 - val_mse: 1934169984.0000\n",
      "Epoch 139/400\n",
      "1314/1314 [==============================] - 0s 87us/sample - loss: 21908.1849 - mse: 1006104384.0000 - val_loss: 25890.9499 - val_mse: 1940866432.0000\n",
      "Epoch 140/400\n",
      "1314/1314 [==============================] - 0s 104us/sample - loss: 20818.9116 - mse: 928552256.0000 - val_loss: 25983.9270 - val_mse: 1946884864.0000\n",
      "Epoch 141/400\n",
      "1314/1314 [==============================] - 0s 103us/sample - loss: 21792.5586 - mse: 965100096.0000 - val_loss: 26103.5197 - val_mse: 1944215040.0000\n",
      "Epoch 142/400\n",
      "1314/1314 [==============================] - 0s 89us/sample - loss: 21679.5373 - mse: 1012918720.0000 - val_loss: 25675.6223 - val_mse: 1924668672.0000\n",
      "Epoch 143/400\n",
      "1314/1314 [==============================] - 0s 119us/sample - loss: 21178.6141 - mse: 919392704.0000 - val_loss: 25995.9641 - val_mse: 1928155776.0000\n",
      "Epoch 144/400\n",
      "1314/1314 [==============================] - 0s 99us/sample - loss: 20436.5116 - mse: 842793984.0000 - val_loss: 25881.7770 - val_mse: 1937614976.0000\n",
      "Epoch 145/400\n",
      "1314/1314 [==============================] - 0s 103us/sample - loss: 20571.7191 - mse: 856602816.0000 - val_loss: 25920.9798 - val_mse: 1939927808.0000\n",
      "Epoch 146/400\n",
      "1314/1314 [==============================] - 0s 111us/sample - loss: 21245.5974 - mse: 957751680.0000 - val_loss: 26057.9847 - val_mse: 1943898752.0000\n",
      "Epoch 147/400\n",
      "1314/1314 [==============================] - 0s 98us/sample - loss: 21784.3460 - mse: 995684672.0000 - val_loss: 25972.4512 - val_mse: 1939308288.0000\n",
      "Epoch 148/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314/1314 [==============================] - 0s 101us/sample - loss: 20832.8522 - mse: 881383360.0000 - val_loss: 25955.0085 - val_mse: 1935614464.0000\n",
      "Epoch 149/400\n",
      "1314/1314 [==============================] - 0s 80us/sample - loss: 21216.7809 - mse: 867073600.0000 - val_loss: 26518.5108 - val_mse: 1984443136.0000\n",
      "Epoch 150/400\n",
      "1314/1314 [==============================] - 0s 78us/sample - loss: 21092.5170 - mse: 915289024.0000 - val_loss: 26468.7997 - val_mse: 1984364544.0000\n",
      "Epoch 151/400\n",
      "1314/1314 [==============================] - 0s 82us/sample - loss: 21428.0950 - mse: 948866240.0000 - val_loss: 25886.1365 - val_mse: 1941449216.0000\n",
      "Epoch 152/400\n",
      "1314/1314 [==============================] - 0s 80us/sample - loss: 20697.1171 - mse: 861655360.0000 - val_loss: 26078.0321 - val_mse: 1940180096.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fef84ac4eb8>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X.iloc[0].shape\n",
    "\n",
    "keras = tf.keras\n",
    "model = keras.Sequential([\n",
    " keras.layers.Dense(100, input_shape=input_shape, activation='relu'),\n",
    " keras.layers.Dropout(0.3),\n",
    " keras.layers.Dense(80, activation='relu'),\n",
    " keras.layers.Dropout(0.3),\n",
    " keras.layers.Dense(10, activation='relu'),\n",
    " keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.Huber(), \n",
    "    optimizer='adam',\n",
    "    metrics=[\"mse\"])\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid) , \n",
    "          callbacks=[early_stopping],\n",
    "          epochs=400\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = bib.prepare_data(pd, file='test.csv')\n",
    "\n",
    "test_X,test_y = bib.split_data(data, with_y=False)\n",
    "\n",
    "test_X = ce.transform(test_X)\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 13:45:29.432799 140670015190656 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame()\n",
    "res['Id'] = pd.to_numeric(test_data['Id'])\n",
    "res['SalePrice'] = model.predict(test_X)[:,0][:-1]\n",
    "res.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
